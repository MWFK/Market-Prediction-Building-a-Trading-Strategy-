{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018992,
     "end_time": "2021-02-04T15:08:15.552034",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.533042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Kudos (massive respect for sharing, even when it's not perfect)\n",
    "https://www.kaggle.com/a763337092/blending-tensorflow-and-pytorch\n",
    "\n",
    "### Pytorch source code:\n",
    "https://www.kaggle.com/a763337092/neural-network-starter-pytorch-version<br/>\n",
    "https://www.kaggle.com/a763337092/pytorch-resnet-starter-training\n",
    "\n",
    "### Tensorflow source code:\n",
    "https://www.kaggle.com/code1110/jane-street-with-keras-nn-overfit <br/>\n",
    "\n",
    "P.S.<br/>\n",
    "Be aware that the model maybe **overfitting**.<br/>\n",
    "As you can this, this notebook it based on the effort of many other competitors, and I was so curious about their result, so I decided to experiment with their work myself ans hsare it with you in this humble notebook of mine, and hopeful to get even a slightly better Result =)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013956,
     "end_time": "2021-02-04T15:08:15.581137",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.567181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libs & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:15.616734Z",
     "iopub.status.busy": "2021-02-04T15:08:15.615905Z",
     "iopub.status.idle": "2021-02-04T15:08:15.619214Z",
     "shell.execute_reply": "2021-02-04T15:08:15.618655Z"
    },
    "papermill": {
     "duration": 0.023934,
     "end_time": "2021-02-04T15:08:15.619351",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.595417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# from sklearn.metrics import log_loss, roc_auc_score this is way to track down if the model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014775,
     "end_time": "2021-02-04T15:08:15.649205",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.634430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Save/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:15.687869Z",
     "iopub.status.busy": "2021-02-04T15:08:15.687168Z",
     "iopub.status.idle": "2021-02-04T15:08:15.697985Z",
     "shell.execute_reply": "2021-02-04T15:08:15.697277Z"
    },
    "papermill": {
     "duration": 0.03364,
     "end_time": "2021-02-04T15:08:15.698122",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.664482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DATA_PATH = '../input/jane-street-market-prediction/' no need to import the data because we're going to only load pytorch and tensorflow models.\n",
    "CACHE_PATH = '../input/mlp012003weights'\n",
    "\n",
    "def save_pickle(dic, save_path):\n",
    "    with open(save_path, 'wb') as f:\n",
    "    # with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(dic, f)\n",
    "\n",
    "def load_pickle(load_path):\n",
    "    with open(load_path, 'rb') as f:\n",
    "    # with gzip.open(load_path, 'rb') as f:\n",
    "        message_dict = pickle.load(f)\n",
    "    return message_dict\n",
    "\n",
    "f_mean = np.load(f'{CACHE_PATH}/f_mean_online.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015721,
     "end_time": "2021-02-04T15:08:15.730505",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.714784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:15.770788Z",
     "iopub.status.busy": "2021-02-04T15:08:15.769605Z",
     "iopub.status.idle": "2021-02-04T15:08:15.773209Z",
     "shell.execute_reply": "2021-02-04T15:08:15.772636Z"
    },
    "papermill": {
     "duration": 0.026587,
     "end_time": "2021-02-04T15:08:15.773347",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.746760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of the features\n",
    "feat_cols = [f'feature_{i}' for i in range(130)]\n",
    "\n",
    "# list of all the features\n",
    "all_feat_cols = [col for col in feat_cols]\n",
    "\n",
    "# add two more features to the feature list\n",
    "all_feat_cols.extend(['cross_41_42_43', 'cross_1_2'])\n",
    "\n",
    "# resp 1,2,3,4\n",
    "target_cols = ['action', 'action_1', 'action_2', 'action_3', 'action_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01617,
     "end_time": "2021-02-04T15:08:15.805819",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.789649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PyTorch\n",
    "I have used this course before, to be able to understand bacis about about Pytorch:<br/>\n",
    "https://www.udacity.com/course/deep-learning-pytorch--ud188\n",
    "\n",
    "### PyTorch Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:15.845714Z",
     "iopub.status.busy": "2021-02-04T15:08:15.845030Z",
     "iopub.status.idle": "2021-02-04T15:08:16.995516Z",
     "shell.execute_reply": "2021-02-04T15:08:16.996085Z"
    },
    "papermill": {
     "duration": 1.173623,
     "end_time": "2021-02-04T15:08:16.996233",
     "exception": false,
     "start_time": "2021-02-04T15:08:15.822610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014392,
     "end_time": "2021-02-04T15:08:17.025681",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.011289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PyTorch Model\n",
    "\n",
    "I have used this course before, to be able to understand bacis about about Pytorch:<br/>\n",
    "https://www.udacity.com/course/deep-learning-pytorch--ud188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:17.079043Z",
     "iopub.status.busy": "2021-02-04T15:08:17.078328Z",
     "iopub.status.idle": "2021-02-04T15:08:17.081733Z",
     "shell.execute_reply": "2021-02-04T15:08:17.081178Z"
    },
    "papermill": {
     "duration": 0.04166,
     "end_time": "2021-02-04T15:08:17.081894",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.040234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Model&Data fnc\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\n",
    "        \n",
    "        # Applies Dropout to the input. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, \n",
    "        # which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "        # https://keras.io/api/layers/regularization_layers/dropout/\n",
    "        \n",
    "        # Dropout is a regularization technique. You should use it only to reduce variance (validation performance vs training performance).\n",
    "        # It is not intended to reduce the bias, and you should not use it in this way.\n",
    "        # Dropout works by probabilistically removing, or “dropping out,” inputs to a layer, \n",
    "        # which may be input variables in the data sample or activations from a previous layer.\n",
    "        # With dropout (dropout rate less than some small value), the accuracy will gradually increase and loss will gradually decrease first\n",
    "        # When you increase dropout beyond a certain threshold, it results in the model not being able to fit properly.\n",
    "        # https://stackoverflow.com/questions/59044351/can-dropout-increases-training-data-performance\n",
    "        \n",
    "        # Dropout prevents overfitting due to a layer's \"over-reliance\" on a few of its inputs. Because these inputs aren't always present \n",
    "        # during training (i.e. they are dropped at random), the layer learns to use all of its inputs, improving generalization.\n",
    "        # https://stats.stackexchange.com/questions/374742/does-dropout-regularization-prevent-overfitting-due-to-too-many-iterations\n",
    "        \n",
    "        # The default interpretation of the dropout hyperparameter is the probability of training a given node in a layer, \n",
    "        # where 1.0 means no dropout, and 0.0 means no outputs from the layer. \n",
    "        # A good value for dropout in a hidden layer is between 0.5 and 0.8. Input layers use a larger dropout rate, such as of 0.8.\n",
    "        # https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "        \n",
    "        self.dropout0 = nn.Dropout(0.8) # 0.2\n",
    "\n",
    "        dropout_rate = 0.5 # 0.2\n",
    "        hidden_size = 256\n",
    "        \n",
    "        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense5 = nn.Linear(hidden_size+hidden_size, len(target_cols))\n",
    "\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "        self.PReLU = nn.PReLU()\n",
    "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        # self.GeLU = nn.GELU()\n",
    "        self.RReLU = nn.RReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm0(x)\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x1 = self.dense1(x)\n",
    "        x1 = self.batch_norm1(x1)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x1 = self.LeakyReLU(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "\n",
    "        x = torch.cat([x, x1], 1)\n",
    "\n",
    "        x2 = self.dense2(x)\n",
    "        x2 = self.batch_norm2(x2)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x2 = self.LeakyReLU(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "\n",
    "        x3 = self.dense3(x)\n",
    "        x3 = self.batch_norm3(x3)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x3 = self.LeakyReLU(x3)\n",
    "        x3 = self.dropout3(x3)\n",
    "\n",
    "        x = torch.cat([x2, x3], 1)\n",
    "\n",
    "        x4 = self.dense4(x)\n",
    "        x4 = self.batch_norm4(x4)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.PReLU(x)\n",
    "        x4 = self.LeakyReLU(x4)\n",
    "        x4 = self.dropout4(x4)\n",
    "\n",
    "        x = torch.cat([x3, x4], 1)\n",
    "\n",
    "        x = self.dense5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01666,
     "end_time": "2021-02-04T15:08:17.113660",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.097000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PyTorch on CPU or GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:17.150917Z",
     "iopub.status.busy": "2021-02-04T15:08:17.150004Z",
     "iopub.status.idle": "2021-02-04T15:08:17.153653Z",
     "shell.execute_reply": "2021-02-04T15:08:17.154362Z"
    },
    "papermill": {
     "duration": 0.025516,
     "end_time": "2021-02-04T15:08:17.154561",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.129045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Since we're going to onyl load the model, then use it for inference, then it's better to use cpu\n",
    "# Otherwise, you want to retrain the model, then enable the GPU for faster calculations\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "    torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print('using device: cpu')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015159,
     "end_time": "2021-02-04T15:08:17.186743",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.171584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PyTorch Load Model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:17.225868Z",
     "iopub.status.busy": "2021-02-04T15:08:17.225149Z",
     "iopub.status.idle": "2021-02-04T15:08:17.581581Z",
     "shell.execute_reply": "2021-02-04T15:08:17.580816Z"
    },
    "papermill": {
     "duration": 0.379513,
     "end_time": "2021-02-04T15:08:17.581742",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.202229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "\n",
    "model_list = []\n",
    "tmp = np.zeros(len(feat_cols))\n",
    "for _fold in range(NFOLDS):\n",
    "    torch.cuda.empty_cache()\n",
    "    model = Model()\n",
    "    model.to(device)\n",
    "    model_weights = f\"{CACHE_PATH}/online_model{_fold}.pth\"\n",
    "    #model.load_state_dict(torch.load(model_weights))\n",
    "    model.load_state_dict(torch.load(model_weights, map_location=device))\n",
    "    model.eval()\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015458,
     "end_time": "2021-02-04T15:08:17.613927",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.598469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TensorFlow\n",
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:17.653112Z",
     "iopub.status.busy": "2021-02-04T15:08:17.652273Z",
     "iopub.status.idle": "2021-02-04T15:08:24.429592Z",
     "shell.execute_reply": "2021-02-04T15:08:24.428865Z"
    },
    "papermill": {
     "duration": 6.79999,
     "end_time": "2021-02-04T15:08:24.429724",
     "exception": false,
     "start_time": "2021-02-04T15:08:17.629734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015693,
     "end_time": "2021-02-04T15:08:24.461721",
     "exception": false,
     "start_time": "2021-02-04T15:08:24.446028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TensorFlow model\n",
    "\n",
    "To understand the following code, refer to my detailed notebook: <br/>\n",
    "[Explanation of the model](https://www.kaggle.com/mouafekmk/simple-mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:24.511385Z",
     "iopub.status.busy": "2021-02-04T15:08:24.510653Z",
     "iopub.status.idle": "2021-02-04T15:08:24.861054Z",
     "shell.execute_reply": "2021-02-04T15:08:24.860280Z"
    },
    "papermill": {
     "duration": 0.383708,
     "end_time": "2021-02-04T15:08:24.861212",
     "exception": false,
     "start_time": "2021-02-04T15:08:24.477504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1111\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# fit\n",
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 4096\n",
    "hidden_units = [160, 160, 160]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(SEED)\n",
    "clf = create_mlp(len(feat_cols), 5, hidden_units, dropout_rates, label_smoothing, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018895,
     "end_time": "2021-02-04T15:08:24.899458",
     "exception": false,
     "start_time": "2021-02-04T15:08:24.880563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TensorFlow Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:24.935998Z",
     "iopub.status.busy": "2021-02-04T15:08:24.935298Z",
     "iopub.status.idle": "2021-02-04T15:08:24.996952Z",
     "shell.execute_reply": "2021-02-04T15:08:24.997513Z"
    },
    "papermill": {
     "duration": 0.081704,
     "end_time": "2021-02-04T15:08:24.997733",
     "exception": false,
     "start_time": "2021-02-04T15:08:24.916029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model and save it with \n",
    "#clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "#clf.save(f'model.h5')\n",
    "\n",
    "# Load the Fitted model\n",
    "# !ls ../input/jane-street-with-keras-nn-overfit/\n",
    "clf.load_weights('../input/jane-street-with-keras-nn-overfit/model.h5')\n",
    "\n",
    "# If you have several models, the you can store into a list\n",
    "#tf_models = [clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016189,
     "end_time": "2021-02-04T15:08:25.030779",
     "exception": false,
     "start_time": "2021-02-04T15:08:25.014590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T15:08:25.077804Z",
     "iopub.status.busy": "2021-02-04T15:08:25.077097Z",
     "iopub.status.idle": "2021-02-04T15:13:31.346457Z",
     "shell.execute_reply": "2021-02-04T15:13:31.345926Z"
    },
    "papermill": {
     "duration": 306.299549,
     "end_time": "2021-02-04T15:13:31.346601",
     "exception": false,
     "start_time": "2021-02-04T15:08:25.047052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15219it [05:06, 49.70it/s]\n"
     ]
    }
   ],
   "source": [
    "th = 0.5 # 0.5 0.501 0.0502 0.053 did not have an effect\n",
    "import janestreet\n",
    "janestreet.competition.make_env.__called__ = False\n",
    "\n",
    "env = janestreet.make_env()\n",
    "env_iter = env.iter_test()\n",
    "\n",
    "#test_df has one single row of data with all the feautures\n",
    "# pred_dfd has 1 or 0 which is an action that comes from test_df\n",
    "\n",
    "for (test_df, pred_df) in tqdm(env_iter):\n",
    "\n",
    "    # Data Processing\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, feat_cols].values\n",
    "        \n",
    "        # if there is only one value eqauls nan, then x_tt.sum will return nan, then np.isnan will be true, and enters the loop\n",
    "        if np.isnan(x_tt.sum()):\n",
    "            # Replace NaN with zero and infinity with large finite numbers (default behaviour)\n",
    "            x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean # the score goew down if we take the if statement\n",
    "\n",
    "    \n",
    "        cross_41_42_43 = x_tt[:, 41] + x_tt[:, 42] + x_tt[:, 43]\n",
    "        cross_1_2 = x_tt[:, 1] / (x_tt[:, 2] + 1e-5)\n",
    "        feature_inp = np.concatenate((x_tt, np.array(cross_41_42_43).reshape(x_tt.shape[0], 1), np.array(cross_1_2).reshape(x_tt.shape[0], 1),), axis=1)\n",
    "\n",
    "        \n",
    "        # PytTorch prediction \n",
    "        torch_pred = np.zeros((1, len(target_cols)))\n",
    "        for model in model_list:\n",
    "            torch_pred += model(torch.tensor(feature_inp, dtype=torch.float).to(device)).sigmoid().detach().cpu().numpy() / NFOLDS\n",
    "        torch_pred = np.median(torch_pred)\n",
    "\n",
    "        \n",
    "        # TensofFlow prediction\n",
    "        # I foyu have several TF models then use\n",
    "        #tf_pred = np.median(np.mean([model(x_tt, training = False).numpy() for model in tf_models],axis=0))\n",
    "        # If you have only one model then use\n",
    "        tf_pred = np.median(clf(x_tt))\n",
    "\n",
    "        \n",
    "        # PyTorch and TensorFlow Average prediction\n",
    "        pred = torch_pred * 0.4 + tf_pred * 0.6\n",
    "        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n",
    "        \n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "        \n",
    "    env.predict(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.870201,
     "end_time": "2021-02-04T15:13:33.080477",
     "exception": false,
     "start_time": "2021-02-04T15:13:32.210276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 323.606751,
   "end_time": "2021-02-04T15:13:34.049626",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-04T15:08:10.442875",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
